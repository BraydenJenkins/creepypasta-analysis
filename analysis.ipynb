{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/creepypastas.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and prepare the data\n",
    "\n",
    "# drop invalid creepypasta row (advertisement)\n",
    "df = df.drop(index=2511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn estimated_reading_time into a number\n",
    "print(df['estimated_reading_time'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated_reading_time is either \"X minutes\", \"X minut\", \"< 1 minute\" or nan\n",
    "df['estimated_reading_time'] = df['estimated_reading_time'].str.replace(' minutes', '')\n",
    "df['estimated_reading_time'] = df['estimated_reading_time'].str.replace('< 1 minute', '1')\n",
    "df['estimated_reading_time'] = df['estimated_reading_time'].str.replace(' minut', '')\n",
    "# convert to numeric\n",
    "df['estimated_reading_time'] = pd.to_numeric(df['estimated_reading_time'])\n",
    "df.head(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn date into a datetime\n",
    "df['publish_date'] = pd.to_datetime(df['publish_date'])\n",
    "df.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ratings to see distribution\n",
    "plot = df['average_rating'].plot.hist(bins=25)\n",
    "plot.set_xlabel('Average Rating')\n",
    "plot.title.set_text('Distribution of Average Ratings')\n",
    "# ratings are skewed left, most ratings are between 6.5 and 8.5\n",
    "df['average_rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reading times to see distribution\n",
    "plot = df['estimated_reading_time'].plot.hist(bins=50)\n",
    "plot.set_xlabel('Estimated Reading Time (minutes)')\n",
    "plot.title.set_text('Distribution of Estimated Reading Times')\n",
    "# most stories are relatively short\n",
    "print(df['estimated_reading_time'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the popularity of creepypastas over time\n",
    "# let's plot month by month how many creepypastas were published\n",
    "stories_per_year = df['publish_date'].dt.year.value_counts()\n",
    "plot = plt.plot(stories_per_year.sort_index())\n",
    "plt.title('Number of Creepypastas Published per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Creepypastas')\n",
    "# huge spike in 2012 that seems to stay for a couple of years, then a resurgence in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there a correlation between number of stories published and the time of year?\n",
    "# let's plot month by month how many creepypastas were published\n",
    "stories_per_month = df['publish_date'].dt.month.value_counts()\n",
    "plot = plt.plot(stories_per_month.sort_index())\n",
    "plt.title('Number of Creepypastas Published per Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Creepypastas')\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct','Nov', 'Dec']\n",
    "ticks = plt.xticks(stories_per_month.sort_index().index, months)\n",
    "# pretty large spike in October, potentially due to Halloween"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesting basic insights so far.\n",
    "# let's dig deeper into the data\n",
    "# do shorter stories get higher ratings?\n",
    "plot = plt.plot(df['average_rating'], df['estimated_reading_time'], 'o')\n",
    "plt.title('Average Rating vs. Estimated Reading Time')\n",
    "plt.xlabel('Average Rating')\n",
    "plt.ylabel('Estimated Reading Time (minutes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's dig into the tags and categories\n",
    "# what are the most popular tags?\n",
    "\n",
    "tags = []\n",
    "tag_dict = {}\n",
    "for tag in df['tags']:\n",
    "    if type(tag) == str:\n",
    "        # check for multiple tags\n",
    "        tags_in_entry = tag.split(', ')\n",
    "        if(len(tags_in_entry) > 1):\n",
    "            for tag in tags_in_entry:\n",
    "                # clean tag and add to list and dict\n",
    "                tag = tag.replace('\\n','')\n",
    "                tag = tag.strip()\n",
    "                tags.append(tag)\n",
    "                # increment tag count in dict\n",
    "                tag_dict[tag] = tag_dict.get(tag, 0) + 1\n",
    "        else:\n",
    "            tag = tag.replace('\\n','')\n",
    "            tags.append(tag)\n",
    "            tag_dict[tag] = tag_dict.get(tag, 0) + 1\n",
    "# remove duplicates\n",
    "tags = list(set(tags))\n",
    "# sort dictionary by value\n",
    "tag_dict = dict(sorted(tag_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "print(\"The 5 most popular creepypasta tags are:\")\n",
    "for i in range(5):\n",
    "    print(list(tag_dict.keys())[i], \":\", list(tag_dict.values())[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do the same for categories\n",
    "categories = []\n",
    "category_dict = {}\n",
    "for category in df['categories']:\n",
    "    if type(category) == str:\n",
    "        categories_in_entry = category.split(', ')\n",
    "        if(len(categories_in_entry) > 1):\n",
    "            for category in categories_in_entry:\n",
    "                category = category.replace('\\n','')\n",
    "                # some entries have \"Please wait...\" as a category on accident, let's remove those\n",
    "                category = category.replace('Please wait...', '')\n",
    "                category = category.strip()\n",
    "                \n",
    "                \n",
    "                categories.append(category)\n",
    "                category_dict[category] = category_dict.get(category, 0) + 1\n",
    "        else:\n",
    "            # some entries have \"Please wait...\" as a category on accident, let's remove those\n",
    "            category = category.replace('Please wait...', '')\n",
    "            category = category.replace('\\n','')\n",
    "            category = category.strip()\n",
    "            categories.append(category)\n",
    "            category_dict[category] = category_dict.get(category, 0) + 1\n",
    "# remove duplicates\n",
    "categories = list(set(categories))\n",
    "# sort dictionary by value\n",
    "category_dict = dict(sorted(category_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "print(\"The 10 most popular creepypasta categories are:\")\n",
    "for i in range(10):\n",
    "    print(list(category_dict.keys())[i], \":\", list(category_dict.values())[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmm, lot's of beings and entities! Is there a correlation between the category and the average rating?\n",
    "# let's plot the average rating for each category\n",
    "category_average_ratings = {}\n",
    "all_ratings = []\n",
    "for category in categories:\n",
    "    # print(category)\n",
    "    # get avg rating from stories that have this category (stories may have multiple)\n",
    "    rating = df[df['categories'].str.contains(category)]['average_rating'].mean()\n",
    "    category_average_ratings[category] = rating\n",
    "    all_ratings.append(rating)\n",
    "\n",
    "# sort dict by avg rating\n",
    "category_average_ratings = dict(sorted(category_average_ratings.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "figure = plt.figure(figsize=(15, 10))\n",
    "\n",
    "plot = plt.bar(category_average_ratings.keys(), category_average_ratings.values())\n",
    "\n",
    "ticks = plt.xticks(rotation='vertical')\n",
    "\n",
    "ax = plt.gca()\n",
    "ymin = min(all_ratings) - 0.5\n",
    "ymax = max(all_ratings) + 0.5\n",
    "ax.set_ylim([ymin, ymax])\n",
    "\n",
    "plt.title('Average Rating by Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it appears that the highest rated creepypastas, on average, are those with happy endings!\n",
    "# how many creepypastas have happy endings?\n",
    "happy_endings = df[df['categories'].str.contains('Happy Endings')]['categories'].count()\n",
    "print(\"Number of creepypastas with happy endings:\", happy_endings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty small sample size! Which makes sense, creepypastas are supposed to be scary and unsettling\n",
    "# let's look at the next highest rated category, True Scary Stories\n",
    "true_scary_stories = df[df['categories'].str.contains('True Scary Stories')]\n",
    "true_scary_stories_count = true_scary_stories['categories'].count()\n",
    "print(\"Number of creepypastas with true scary stories:\", true_scary_stories_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only a single creepypasta with a true scary story! \n",
    "# This also makes sense, creepypastas are supposed to be fictional\n",
    "# Let's look at this one true story.\n",
    "true_story = true_scary_stories.iloc[0]\n",
    "print(\"The true story: \", true_story['story_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after doing some research, it turns out that this story is totally fake.\n",
    "# https://en.wikipedia.org/wiki/Dybbuk_box\n",
    "\n",
    "# let's look at the next highest rated category, Natural Disasters and Storms\n",
    "natural_disasters = df[df['categories'].str.contains('Natural Disasters and Storms')]\n",
    "natural_disasters_count = natural_disasters['categories'].count()\n",
    "print(\"Number of creepypastas with natural disasters:\", natural_disasters_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns out the highest rated categories all have a super small sample size. Let's see how many stories of each category there are\n",
    "\n",
    "figure = plt.figure(figsize=(15, 10))\n",
    "plot = plt.bar(category_dict.keys(), category_dict.values())\n",
    "ticks = plt.xticks(rotation='vertical')\n",
    "plt.title('Number of Creepypastas per Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do some analysis on the text itself\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# get all the words from the creepypastas\n",
    "all_text_content = '\\n'.join(df['body'])\n",
    "print(\"Total characters in all creepypastas:\", len(all_text_content))\n",
    "\n",
    "# get all words\n",
    "tokens = [t.lower() for t in nltk.word_tokenize(all_text_content) if t.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all words excluding stopwords\n",
    "words = [w for w in tokens if not w in stop_words]\n",
    "print(\"Total words in all creepypastas (excluding stopwords):\", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_words = set(words)\n",
    "# https://en.wikipedia.org/wiki/Lexical_diversity\n",
    "lexical_diversity = len(distinct_words) / len(words)\n",
    "\n",
    "print(\"Total distinct words:\", len(distinct_words))\n",
    "print(\"Lexical diversity:\", lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a fun thing to look for: collocations\n",
    "# this is a pair of words that occur together often in the text\n",
    "# textual analysis inspired by https://medium.com/@finalfire/visualizing-data-from-norwegian-wood-by-haruki-murakami-502e117fdcc6\n",
    "\n",
    "ntext = nltk.Text(tokens)\n",
    "ntext.collocations(window_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun to see, though with such a large corpus, the collocations are not very interesting\n",
    "# let's look at the most common words\n",
    "fdist = nltk.FreqDist(words)\n",
    "most_common = fdist.most_common(20)\n",
    "\n",
    "figure = plt.figure(figsize=(15, 10))\n",
    "plot = plt.bar([x[0] for x in most_common], [x[1] for x in most_common])\n",
    "ticks = plt.xticks(rotation=45)\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Most Common Words in Creepypastas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once again, not very exciting, but interestingly, one of the most common words is 'eyes'\n",
    "# eyes can indeed be very creepy.\n",
    "# aditionally, 'night' is a common word, which makes sense, as many scary stories take place at night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the most common words in the titles now\n",
    "all_titles = '\\n'.join(df['story_name'])\n",
    "print(\"Total characters in all creepypasta titles:\", len(all_titles))\n",
    "title_tokens = [t.lower() for t in nltk.word_tokenize(all_titles) if t.isalpha()]\n",
    "title_words = [w for w in title_tokens if not w in stop_words]\n",
    "title_fdist = nltk.FreqDist(title_words)\n",
    "title_most_common = title_fdist.most_common(20)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.bar([x[0] for x in title_most_common], [x[1] for x in title_most_common])\n",
    "ticks = plt.xticks(rotation=45)\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "title = plt.title('Most Common Words in Creepypasta Titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ah, much more interesting! (Likely because titles typically have much less generic text)\n",
    "# turns out men are really scary, along with dark houses at night!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about words that rarely occur?\n",
    "# https://en.wikipedia.org/wiki/Hapax_legomenon\n",
    "rare_words = fdist.hapaxes()\n",
    "print(\"Total words that occur only once (hapax legomena):\", len(rare_words))\n",
    "# let's pick some at random\n",
    "import random\n",
    "random_words = random.sample(rare_words, 10)\n",
    "string = \"Random sample of hapax legomena: \"\n",
    "rand_words = ', '.join(random_words)\n",
    "string += rand_words\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just from a few samples, it seems like a lot of these words are typos or made up words. others are totally unexpected\n",
    "# that makes total sense, but is kinda disappointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's take the highest rated story and perform textual analysis\n",
    "highest_rated = df[df['average_rating'] == df['average_rating'].max()].iloc[0]\n",
    "print(\"Highest rated creepypasta:\", highest_rated['story_name'])\n",
    "highest_rated_text = highest_rated['body']\n",
    "print(\"Total characters in '\"+highest_rated['story_name']+\"':\", len(highest_rated_text))\n",
    "highest_rated_tokens = [t.lower() for t in nltk.word_tokenize(highest_rated_text) if t.isalpha()]\n",
    "highest_rated_words = [w for w in highest_rated_tokens if not w in stop_words]\n",
    "highest_rated_fdist = nltk.FreqDist(highest_rated_words)\n",
    "highest_rated_most_common = highest_rated_fdist.most_common(20)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.bar([x[0] for x in highest_rated_most_common], [x[1] for x in highest_rated_most_common])\n",
    "ticks = plt.xticks(rotation=45)\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "title = plt.title('Most Common Words in '+highest_rated['story_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most common words alone give a pretty good idea of what the story is about (it is freaky, be warned!)\n",
    "# let's look at the collocations\n",
    "highest_rated_ntext = nltk.Text(highest_rated_tokens)\n",
    "highest_rated_ntext.collocations(window_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to find the shape of the story, inspired by Kurt Vonnegut\n",
    "# https://www.youtube.com/watch?v=oP3c1h8v2ZQ\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "\n",
    "story_text = highest_rated['body']\n",
    "story_sentences = [s for s in nltk.sent_tokenize(story_text)]\n",
    "print(\"Total sentences in '\"+highest_rated['story_name']+\"':\", len(story_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = [sia.polarity_scores(s)['compound'] for s in story_sentences]\n",
    "plot = plt.plot(sentiment_scores)\n",
    "plt.xlabel('Sentence')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.title('Sentiment Score of Sentences in \\''+highest_rated['story_name']+\"\\'\")\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_ylim([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's try to get a running average over a sentence window to get a better idea of the shape of the story\n",
    "window_size = 15\n",
    "\n",
    "sentiment_series = pd.Series(sentiment_scores)\n",
    "sentiment_mean = sentiment_series.rolling(window_size).mean().values\n",
    "x_axis = sentiment_series.index\n",
    "\n",
    "plot = plt.plot(x_axis, sentiment_mean)\n",
    "plt.plot(x_axis, [0 for i in range(len(x_axis))], 'k--')\n",
    "\n",
    "plt.xlabel('Sentence') \n",
    "plt.ylabel('Compound Sentiment Score')\n",
    "title = plt.title('Compound Sentiment Score of Sentences in \\''+highest_rated['story_name']+\"\\'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can see much more of the story's shape\n",
    "# The story is overall negative, with a few positive spikes\n",
    "# let's view the lowest point and highest point of the story\n",
    "# this is the point in which the average sentiment score within the window is the lowest/highest\n",
    "import numpy as np\n",
    "lowest_point = np.nanmin(sentiment_mean)\n",
    "lowest_point_index = np.where(sentiment_mean == lowest_point)[0][0]\n",
    "print(\"Lowest point of the story:\", story_sentences[lowest_point_index])\n",
    "print(\"Lowest point sentiment score:\", lowest_point)\n",
    "print()\n",
    "highest_point = np.nanmax(sentiment_mean)\n",
    "highest_point_index = np.where(sentiment_mean == highest_point)[0][0]\n",
    "print(\"Highest point of the story:\", story_sentences[highest_point_index])\n",
    "print(\"Highest point sentiment score:\", highest_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during the low point, the narrator is describing pain from an injury. Makes sense!\n",
    "# during the high point, the narrator is using language such as 'I commanded', which could potentially be seen as positive / powerful\n",
    "# but overall, the high point is still only very slightly positive, landing it in neutral territory.\n",
    "# looking at the sentence per sentence scores, it seems there is one very positive sentence that is bringing the average up.\n",
    "# what is this sentence?\n",
    "highest_sentence_index = np.argmax(sentiment_scores)\n",
    "print(\"Highest sentiment sentence:\", story_sentences[highest_sentence_index])\n",
    "print(\"Highest sentiment score:\", sentiment_scores[highest_sentence_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ah! the narrator is finally successful in his task (which in this case, is stabilization of his body) (long story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do some machine learning!\n",
    "\n",
    "# let's try to predict the average rating of a creepypasta based on the categories and estimated reading time.\n",
    "\n",
    "# I think we need to encode the categories somehow\n",
    "# we will use sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df['categories'] = ml_df['categories'].apply(lambda x: x.replace('\\n', ''))\n",
    "ml_df['categories'] = ml_df['categories'].apply(lambda x: x.replace('Please wait...', ''))\n",
    "ml_df['categories'] = ml_df['categories'].apply(lambda x: x.split(', '))\n",
    "ml_df['categories'] = ml_df['categories'].apply(lambda x: [y.strip() for y in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using multilabelbinarizer to encode categories since a story can have multiple categories\n",
    "mlb = MultiLabelBinarizer()\n",
    "categories_encoded = pd.DataFrame(mlb.fit_transform(ml_df['categories']), columns=mlb.classes_, index=ml_df.index)\n",
    "ml_df_encoded = pd.concat([ml_df.drop(['categories', 'average_rating', 'tags', 'body', 'story_name', 'publish_date'], axis=1), categories_encoded], axis=1)\n",
    "ml_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split!\n",
    "X_train, X_test, y_train, y_test = train_test_split(ml_df_encoded, ml_df['average_rating'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model (linear regression isn't great, let's try random forest)\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = pd.DataFrame(columns=['story_name', 'predicted_rating', 'categories', 'estimated_reading_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have fit a model, let's get predictions for randomly generated creepypastas\n",
    "\n",
    "# let's use openai to generate random titles, their categories, and their estimated reading times\n",
    "# the title is just for fun, we will use the categories and estimated reading time for our model\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You generate creepypasta titles, categories, and estimated reading times. Valid categories are:\"\n",
    "for category in ml_df_encoded.columns[8:]:\n",
    "    system_prompt += \"\\n\" + category\n",
    "\n",
    "print(system_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": system_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"I can do that!\"},\n",
    "        {\"role\": \"user\", \"content\": \"Generate a creepypasta title, category, and estimated reading time.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Title: The Creepy Pasta\\nCategories: Drugs and Addictions, Magic\\nEstimated Reading Time: 5\"},\n",
    "        {\"role\": \"user\", \"content\": \"Generate a unique creepypasta title, categories, and estimated reading time.\"}\n",
    "    ],\n",
    "    temperature=1.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = response['choices'][0]['message']['content']\n",
    "content = content.split('\\n')\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = content[0].split(':')[1].strip()\n",
    "categories = content[1].split(':')[1].strip().split(', ')\n",
    "reading_time = content[2].split(':')[1].strip()\n",
    "if ' minutes' in reading_time:\n",
    "    reading_time = reading_time.replace(' minutes', '')\n",
    "    reading_time = int(reading_time)\n",
    "\n",
    "print(\"Title:\", title)\n",
    "print(\"Categories:\", categories)\n",
    "print(\"Reading Time:\", reading_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted rating\n",
    "\n",
    "generated_df = pd.DataFrame(columns=ml_df_encoded.columns)\n",
    "generated_df.loc[0] = 0\n",
    "generated_df['estimated_reading_time'] = reading_time\n",
    "for category in categories:\n",
    "    if category in generated_df.columns:\n",
    "        print(\"Found category:\", category)\n",
    "        generated_df[category] = 1\n",
    "    else:\n",
    "        print(\"Unkown category:\", category)\n",
    "    \n",
    "generated_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rating = model.predict(generated_df)\n",
    "print(\"Predicted rating for '\"+title+\"':\", predicted_rating[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = pd.concat([predicted_ratings, pd.DataFrame([[title, predicted_rating[0], categories, reading_time]], columns=['story_name', 'predicted_rating', 'categories', 'estimated_reading_time'])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have a dataframe of predicted ratings (based on category and reading time) for randomly generated creepypastas!\n",
    "predicted_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# according to the analysis above, people seem to dislike spiders and insects.\n",
    "# additionally longer creepypastas have higher ratings\n",
    "# with this knowledge, let's try to create a poorly rated creepypasta\n",
    "\n",
    "bad_creepypasta = pd.DataFrame(columns=ml_df_encoded.columns)\n",
    "bad_creepypasta.loc[0] = 0\n",
    "bad_creepypasta['estimated_reading_time'] = 1\n",
    "bad_creepypasta['Spiders'] = 1\n",
    "bad_creepypasta['Insects'] = 1\n",
    "\n",
    "predicted_rating = model.predict(bad_creepypasta)\n",
    "print(\"Predicted rating for the bad creepypasta:\", predicted_rating[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how well this creepypasta does with the same content but alternate reading times\n",
    "\n",
    "bad_creepypasta_reading_times = pd.DataFrame(columns=ml_df_encoded.columns)\n",
    "for i in range(0, 99):\n",
    "    bad_creepypasta_reading_times.loc[i] = 0\n",
    "bad_creepypasta_reading_times['Spiders'] = 1\n",
    "bad_creepypasta_reading_times['Insects'] = 1\n",
    "bad_creepypasta_reading_times['estimated_reading_time'] = [i for i in range(1, 100)]\n",
    "\n",
    "plt.plot(bad_creepypasta_reading_times['estimated_reading_time'], model.predict(bad_creepypasta_reading_times))\n",
    "plt.xlabel('Estimated Reading Time')\n",
    "plt.ylabel('Predicted Rating')\n",
    "title = plt.title('Predicted Rating of Bad Creepypasta by Estimated Reading Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's keep the same reading time but change the content\n",
    "\n",
    "bad_creepypasta_content = pd.DataFrame(columns=ml_df_encoded.columns)\n",
    "for i in range(0, len(categories)):\n",
    "    bad_creepypasta_content.loc[i] = 0\n",
    "bad_creepypasta_content['estimated_reading_time'] = 60\n",
    "for i in range(0,len(categories)):\n",
    "    bad_creepypasta_content.loc[i, categories[i]] = 1\n",
    "\n",
    "figure = plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.plot(category_dict.keys(), model.predict(bad_creepypasta_content))\n",
    "ticks = plt.xticks(rotation='vertical')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Predicted Rating')\n",
    "title = plt.title('Predicted Rating of Short Creepypasta by Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and just for fun to test our model, let's try to create a long creepypasta with a happy ending\n",
    "happy_ending_creepypasta = pd.DataFrame(columns=ml_df_encoded.columns)\n",
    "happy_ending_creepypasta.loc[0] = 0\n",
    "happy_ending_creepypasta['estimated_reading_time'] = 60\n",
    "happy_ending_creepypasta['Feelspastas and Happy Endings'] = 1\n",
    "\n",
    "predicted_rating = model.predict(happy_ending_creepypasta)\n",
    "print(\"Predicted rating for the happy ending creepypasta:\", predicted_rating[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun project! Now we know how to create the best creepypastas, and can predict their ratings!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
